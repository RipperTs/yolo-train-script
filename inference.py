"""
YOLOv8 æ¨ç†æ¨¡å—
æä¾›æ¨¡å‹æ¨ç†å’Œé¢„æµ‹åŠŸèƒ½
"""

import sys
from pathlib import Path
import cv2
import numpy as np
from typing import List, Dict, Union, Tuple
import json
from PIL import Image

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from config import INFERENCE_CONFIG, MODELS_DIR, get_default_device
from config_manager import config_manager
from device_manager import device_manager
from class_manager import class_manager


class YOLOv8Inference:
    """YOLOv8æ¨ç†å™¨ç±»"""
    
    def __init__(self, model_path: str = None, device: str = None):
        """
        åˆå§‹åŒ–æ¨ç†å™¨
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™å°è¯•åŠ è½½æœ€æ–°çš„è®­ç»ƒæ¨¡å‹
            device: æ¨ç†è®¾å¤‡ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®ä¸­çš„è®¾å¤‡æˆ–è‡ªåŠ¨é€‰æ‹©
        """
        self.model = None
        self.model_path = model_path
        self.class_names = self._load_class_names()
        self.device = device
        
        if model_path is None:
            self.model_path = self._find_latest_model()
        
        # è®¾ç½®æ¨ç†è®¾å¤‡
        self._setup_device()
        
        self.load_model()
    
    def _load_class_names(self) -> List[str]:
        """
        ä»ç±»åˆ«ç®¡ç†å™¨åŠ è½½ç±»åˆ«åç§°
        
        Returns:
            ç±»åˆ«åç§°åˆ—è¡¨
        """
        try:
            # ä¼˜å…ˆä»ç±»åˆ«ç®¡ç†å™¨è·å–æœ€æ–°çš„ç±»åˆ«ä¿¡æ¯
            class_names = class_manager.get_class_names()
            
            if class_names:
                print(f"ğŸ“‹ ä»ç±»åˆ«ç®¡ç†å™¨åŠ è½½ç±»åˆ«: {class_names}")
                return class_names
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•ä»dataset.yamlåŠ è½½
            class_names = class_manager.load_classes_from_yaml()
            if class_names:
                print(f"ğŸ“‹ ä»dataset.yamlåŠ è½½ç±»åˆ«: {class_names}")
                return class_names
            
            # æœ€åå¤‡ç”¨ï¼šè¿”å›é€šç”¨ç±»åˆ«åç§°
            print("âš ï¸ æ— æ³•åŠ è½½ç±»åˆ«ä¿¡æ¯ï¼Œä½¿ç”¨é€šç”¨ç±»åˆ«åç§°")
            return [f"class_{i}" for i in range(10)]  # è¿”å›10ä¸ªé€šç”¨ç±»åˆ«
            
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ç±»åˆ«åç§°å¤±è´¥: {e}ï¼Œä½¿ç”¨é€šç”¨ç±»åˆ«åç§°")
            return [f"class_{i}" for i in range(10)]
    
    def _setup_device(self):
        """è®¾ç½®æ¨ç†è®¾å¤‡"""
        if self.device is None:
            # ä»é…ç½®ç®¡ç†å™¨è·å–æ¨ç†è®¾å¤‡è®¾ç½®
            inference_config = config_manager.get_inference_config()
            self.device = inference_config.get("device")
            
            # å¦‚æœé…ç½®ä¸­ä¹Ÿæ²¡æœ‰è®¾å¤‡è®¾ç½®ï¼Œä½¿ç”¨è®­ç»ƒé…ç½®çš„è®¾å¤‡
            if self.device is None:
                training_config = config_manager.get_training_config()
                self.device = training_config.get("device") or get_default_device()
        
        # éªŒè¯å¹¶è®¾ç½®è®¾å¤‡
        if not device_manager.set_device(self.device):
            print(f"âš ï¸ æ— æ³•ä½¿ç”¨æ¨ç†è®¾å¤‡ {self.device}ï¼Œä½¿ç”¨é™çº§è®¾å¤‡")
        
        self.device = device_manager.current_device
        print(f"ğŸ¯ ä½¿ç”¨æ¨ç†è®¾å¤‡: {self.device}")
    
    def _find_latest_model(self) -> str:
        """æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒæ¨¡å‹"""
        model_files = []
        
        # æŸ¥æ‰¾.ptæ–‡ä»¶
        for pattern in ["**/*.pt", "**/*best.pt", "**/best.pt"]:
            model_files.extend(MODELS_DIR.glob(pattern))
        
        if not model_files:
            raise FileNotFoundError(
                f"åœ¨ {MODELS_DIR} ä¸­æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶\n"
                "è¯·å…ˆè¿è¡Œè®­ç»ƒæˆ–æŒ‡å®šæ¨¡å‹è·¯å¾„"
            )
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
        latest_model = max(model_files, key=lambda x: x.stat().st_mtime)
        print(f"è‡ªåŠ¨é€‰æ‹©æœ€æ–°æ¨¡å‹: {latest_model}")
        
        return str(latest_model)
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        try:
            from ultralytics import YOLO
            
            if not Path(self.model_path).exists():
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            
            self.model = YOLO(self.model_path)
            print(f"æ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path}")
            
        except ImportError:
            raise ImportError(
                "æœªå®‰è£…ultralyticsåº“ï¼Œè¯·è¿è¡Œ: pip install ultralytics"
            )
        except Exception as e:
            raise Exception(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
    
    def reload_class_names(self):
        """é‡æ–°åŠ è½½ç±»åˆ«åç§°"""
        self.class_names = self._load_class_names()
    
    def predict_image(self, image_path: str, save_result: bool = True) -> Dict:
        """
        å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œé¢„æµ‹
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            save_result: æ˜¯å¦ä¿å­˜ç»“æœå›¾ç‰‡
            
        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªåŠ è½½")
        
        image_path = Path(image_path)
        if not image_path.exists():
            raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        
        # è·å–å½“å‰æ¨ç†é…ç½®
        inference_config = config_manager.get_inference_config()
        
        # è¿›è¡Œé¢„æµ‹
        results = self.model(
            str(image_path),
            conf=inference_config.get("conf_threshold", INFERENCE_CONFIG["conf_threshold"]),
            iou=inference_config.get("iou_threshold", INFERENCE_CONFIG["iou_threshold"]),
            max_det=inference_config.get("max_det", INFERENCE_CONFIG["max_det"]),
            imgsz=inference_config.get("img_size", INFERENCE_CONFIG["img_size"]),
            device=self.device,  # ä½¿ç”¨é…ç½®çš„è®¾å¤‡
            save=save_result,
            verbose=False
        )
        
        # è§£æç»“æœ
        result = results[0]
        predictions = self._parse_results(result)
        
        return {
            "image_path": str(image_path),
            "image_size": (result.orig_shape[1], result.orig_shape[0]),  # (width, height)
            "predictions": predictions,
            "num_detections": len(predictions)
        }
    
    def predict_batch(self, image_paths: List[str], save_results: bool = True) -> List[Dict]:
        """
        æ‰¹é‡é¢„æµ‹å¤šå¼ å›¾ç‰‡
        
        Args:
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            save_results: æ˜¯å¦ä¿å­˜ç»“æœå›¾ç‰‡
            
        Returns:
            é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªåŠ è½½")
        
        results = []
        
        for image_path in image_paths:
            try:
                result = self.predict_image(image_path, save_result=save_results)
                results.append(result)
                print(f"é¢„æµ‹å®Œæˆ: {image_path}")
            except Exception as e:
                print(f"é¢„æµ‹å¤±è´¥ {image_path}: {e}")
                results.append({
                    "image_path": image_path,
                    "error": str(e),
                    "predictions": [],
                    "num_detections": 0
                })
        
        return results
    
    def _parse_results(self, result) -> List[Dict]:
        """
        è§£æYOLOé¢„æµ‹ç»“æœ
        
        Args:
            result: YOLOç»“æœå¯¹è±¡
            
        Returns:
            è§£æåçš„é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        predictions = []
        
        if result.boxes is not None:
            boxes = result.boxes
            
            for i in range(len(boxes)):
                # è·å–è¾¹ç•Œæ¡†åæ ‡ (xyxyæ ¼å¼)
                box = boxes.xyxy[i].cpu().numpy()
                x1, y1, x2, y2 = box
                
                # è·å–ç½®ä¿¡åº¦
                confidence = float(boxes.conf[i].cpu().numpy())
                
                # è·å–ç±»åˆ«
                class_id = int(boxes.cls[i].cpu().numpy())
                class_name = self.class_names[class_id] if class_id < len(self.class_names) else f"class_{class_id}"
                
                prediction = {
                    "class_id": class_id,
                    "class_name": class_name,
                    "confidence": confidence,
                    "bbox": {
                        "x1": float(x1),
                        "y1": float(y1),
                        "x2": float(x2),
                        "y2": float(y2),
                        "width": float(x2 - x1),
                        "height": float(y2 - y1),
                        "center_x": float((x1 + x2) / 2),
                        "center_y": float((y1 + y2) / 2)
                    }
                }
                
                predictions.append(prediction)
        
        return predictions
    
    def predict_from_array(self, image_array: np.ndarray) -> Dict:
        """
        ä»numpyæ•°ç»„é¢„æµ‹
        
        Args:
            image_array: å›¾ç‰‡æ•°ç»„ (BGRæ ¼å¼)
            
        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªåŠ è½½")
        
        # è¿›è¡Œé¢„æµ‹
        results = self.model(
            image_array,
            conf=INFERENCE_CONFIG["conf_threshold"],
            iou=INFERENCE_CONFIG["iou_threshold"],
            max_det=INFERENCE_CONFIG["max_det"],
            imgsz=INFERENCE_CONFIG["img_size"],
            verbose=False
        )
        
        # è§£æç»“æœ
        result = results[0]
        predictions = self._parse_results(result)
        
        return {
            "image_size": (result.orig_shape[1], result.orig_shape[0]),  # (width, height)
            "predictions": predictions,
            "num_detections": len(predictions)
        }
    
    def visualize_predictions(self, image_path: str, predictions: List[Dict], 
                            output_path: str = None) -> str:
        """
        å¯è§†åŒ–é¢„æµ‹ç»“æœ
        
        Args:
            image_path: åŸå§‹å›¾ç‰‡è·¯å¾„
            predictions: é¢„æµ‹ç»“æœåˆ—è¡¨
            output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„
            
        Returns:
            è¾“å‡ºå›¾ç‰‡è·¯å¾„
        """
        # è¯»å–å›¾ç‰‡
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        
        # ç»˜åˆ¶é¢„æµ‹ç»“æœ
        for pred in predictions:
            bbox = pred["bbox"]
            class_name = pred["class_name"]
            confidence = pred["confidence"]
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            x1, y1, x2, y2 = int(bbox["x1"]), int(bbox["y1"]), int(bbox["x2"]), int(bbox["y2"])
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{class_name}: {confidence:.2f}"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
            cv2.rectangle(image, (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0], y1), (0, 255, 0), -1)
            cv2.putText(image, label, (x1, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)
        
        # ä¿å­˜ç»“æœ
        if output_path is None:
            image_path = Path(image_path)
            output_path = image_path.parent / f"{image_path.stem}_result{image_path.suffix}"
        
        cv2.imwrite(str(output_path), image)
        print(f"å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {output_path}")
        
        return str(output_path)
    
    def save_predictions_json(self, predictions_list: List[Dict], output_path: str):
        """
        ä¿å­˜é¢„æµ‹ç»“æœä¸ºJSONæ–‡ä»¶
        
        Args:
            predictions_list: é¢„æµ‹ç»“æœåˆ—è¡¨
            output_path: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„
        """
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(predictions_list, f, ensure_ascii=False, indent=2)
        
        print(f"é¢„æµ‹ç»“æœå·²ä¿å­˜: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="YOLOv8æ¨ç†è„šæœ¬")
    parser.add_argument("--model", type=str, help="æ¨¡å‹è·¯å¾„")
    parser.add_argument("--image", type=str, help="å•å¼ å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--images", type=str, help="å›¾ç‰‡ç›®å½•è·¯å¾„")
    parser.add_argument("--output", type=str, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--save-json", action="store_true", help="ä¿å­˜JSONç»“æœ")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æ¨ç†å™¨
    inference = YOLOv8Inference(model_path=args.model)
    
    if args.image:
        # å•å¼ å›¾ç‰‡é¢„æµ‹
        result = inference.predict_image(args.image)
        print(f"æ£€æµ‹åˆ° {result['num_detections']} ä¸ªç›®æ ‡")
        
        if args.save_json:
            json_path = Path(args.image).with_suffix('.json')
            inference.save_predictions_json([result], str(json_path))
    
    elif args.images:
        # æ‰¹é‡é¢„æµ‹
        image_dir = Path(args.images)
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            image_files.extend(image_dir.glob(ext))
        
        if not image_files:
            print(f"åœ¨ {image_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return
        
        results = inference.predict_batch([str(f) for f in image_files])
        
        total_detections = sum(r['num_detections'] for r in results)
        print(f"æ‰¹é‡é¢„æµ‹å®Œæˆï¼Œå…±æ£€æµ‹åˆ° {total_detections} ä¸ªç›®æ ‡")
        
        if args.save_json:
            json_path = image_dir / "predictions.json"
            inference.save_predictions_json(results, str(json_path))


if __name__ == "__main__":
    main()
