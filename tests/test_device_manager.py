#!/usr/bin/env python3
"""
è®¾å¤‡ç®¡ç†å™¨æµ‹è¯•è„šæœ¬
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

def test_device_detection():
    """æµ‹è¯•è®¾å¤‡æ£€æµ‹"""
    print("ğŸ” æµ‹è¯•è®¾å¤‡æ£€æµ‹...")
    
    from device_manager import device_manager
    
    print(f"å½“å‰è®¾å¤‡: {device_manager.current_device}")
    print(f"GPUå¯ç”¨: {device_manager.is_gpu_available()}")
    print(f"å¯ç”¨è®¾å¤‡æ•°é‡: {len(device_manager.available_devices)}")
    
    print("\nğŸ“‹ è®¾å¤‡åˆ—è¡¨:")
    for i, device in enumerate(device_manager.available_devices):
        print(f"  {i+1}. {device['description']}")
        print(f"     ID: {device['id']}")
        print(f"     ç±»å‹: {device['type']}")
        print(f"     å†…å­˜: {device['memory']}")
        print()

def test_device_choices():
    """æµ‹è¯•Gradioè®¾å¤‡é€‰æ‹©"""
    print("ğŸ›ï¸ æµ‹è¯•Gradioè®¾å¤‡é€‰æ‹©...")
    
    from device_manager import get_device_choices_for_gradio, parse_device_choice
    
    choices = get_device_choices_for_gradio()
    print(f"Gradioé€‰æ‹©é¡¹: {choices}")
    
    for choice in choices:
        device_id = parse_device_choice(choice)
        print(f"  '{choice}' -> '{device_id}'")

def test_device_switching():
    """æµ‹è¯•è®¾å¤‡åˆ‡æ¢"""
    print("ğŸ”„ æµ‹è¯•è®¾å¤‡åˆ‡æ¢...")
    
    from device_manager import device_manager
    
    original_device = device_manager.current_device
    print(f"åŸå§‹è®¾å¤‡: {original_device}")
    
    # å°è¯•åˆ‡æ¢åˆ°æ¯ä¸ªå¯ç”¨è®¾å¤‡
    for device in device_manager.available_devices:
        device_id = device['id']
        print(f"\nå°è¯•åˆ‡æ¢åˆ°: {device_id}")
        
        success = device_manager.set_device(device_id)
        if success:
            print(f"âœ… æˆåŠŸåˆ‡æ¢åˆ°: {device_manager.current_device}")
            
            # è·å–æ¨èé…ç½®
            batch_size = device_manager.get_optimal_batch_size(device_id)
            print(f"   æ¨èæ‰¹æ¬¡å¤§å°: {batch_size}")
            
            # éªŒè¯å…¼å®¹æ€§
            compatibility = device_manager.validate_device_compatibility(device_id)
            print(f"   å…¼å®¹æ€§: {compatibility['compatible']}")
            if compatibility['warnings']:
                print(f"   è­¦å‘Š: {compatibility['warnings']}")
            if compatibility['recommendations']:
                print(f"   å»ºè®®: {compatibility['recommendations']}")
        else:
            print(f"âŒ åˆ‡æ¢å¤±è´¥")
    
    # æ¢å¤åŸå§‹è®¾å¤‡
    device_manager.set_device(original_device)
    print(f"\nğŸ”™ æ¢å¤åˆ°åŸå§‹è®¾å¤‡: {device_manager.current_device}")

def test_config_integration():
    """æµ‹è¯•é…ç½®ç®¡ç†å™¨é›†æˆ"""
    print("âš™ï¸ æµ‹è¯•é…ç½®ç®¡ç†å™¨é›†æˆ...")
    
    from config_manager import config_manager
    
    # è·å–è®¾å¤‡ä¿¡æ¯
    device_info = config_manager.get_device_info()
    print("è®¾å¤‡ä¿¡æ¯:")
    for key, value in device_info.items():
        if key != "device_status":  # è·³è¿‡å¤æ‚çš„çŠ¶æ€ä¿¡æ¯
            print(f"  {key}: {value}")
    
    # æµ‹è¯•è®¾å¤‡æ›´æ–°
    available_devices = device_info['available_devices']
    if len(available_devices) > 1:
        test_device = available_devices[1]  # é€‰æ‹©ç¬¬äºŒä¸ªè®¾å¤‡
        print(f"\næµ‹è¯•åˆ‡æ¢åˆ°è®¾å¤‡: {test_device}")
        
        success = config_manager.update_device(test_device)
        if success:
            print("âœ… é…ç½®ç®¡ç†å™¨è®¾å¤‡åˆ‡æ¢æˆåŠŸ")
            
            # è·å–æ¨èè®¾ç½®
            recommendations = config_manager.get_device_recommendations(test_device)
            print(f"æ¨èè®¾ç½®: {recommendations}")
        else:
            print("âŒ é…ç½®ç®¡ç†å™¨è®¾å¤‡åˆ‡æ¢å¤±è´¥")

def test_pytorch_integration():
    """æµ‹è¯•PyTorché›†æˆ"""
    print("ğŸ”¥ æµ‹è¯•PyTorché›†æˆ...")
    
    import torch
    from device_manager import device_manager
    
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        
        for i in range(torch.cuda.device_count()):
            print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
    
    # æµ‹è¯•MPS (Apple Silicon)
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        print("âœ… MPS (Apple Metal) å¯ç”¨")
    else:
        print("âŒ MPS (Apple Metal) ä¸å¯ç”¨")
    
    # æµ‹è¯•å¼ é‡åˆ›å»º
    print("\nğŸ§® æµ‹è¯•å¼ é‡åˆ›å»º:")
    for device in device_manager.available_devices:
        device_id = device['id']
        try:
            if device_id == "cpu":
                tensor = torch.randn(10, 10)
            else:
                tensor = torch.randn(10, 10).to(device_id)
            
            print(f"âœ… {device_id}: å¼ é‡åˆ›å»ºæˆåŠŸ - {tensor.device}")
        except Exception as e:
            print(f"âŒ {device_id}: å¼ é‡åˆ›å»ºå¤±è´¥ - {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ è®¾å¤‡ç®¡ç†å™¨æµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("è®¾å¤‡æ£€æµ‹", test_device_detection),
        ("Gradioé€‰æ‹©", test_device_choices),
        ("è®¾å¤‡åˆ‡æ¢", test_device_switching),
        ("é…ç½®é›†æˆ", test_config_integration),
        ("PyTorché›†æˆ", test_pytorch_integration)
    ]
    
    for name, test_func in tests:
        print(f"\n{'='*20} {name} {'='*20}")
        try:
            test_func()
        except Exception as e:
            print(f"âŒ {name}æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        print("=" * 50)
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()
