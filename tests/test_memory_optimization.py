#!/usr/bin/env python3
"""
å†…å­˜ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•
éªŒè¯å†…å­˜ä¼˜åŒ–æ¨¡å—çš„å„é¡¹åŠŸèƒ½
"""

import sys
import time
import gc
import torch
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from memory_optimizer import MemoryOptimizer, TrainingMemoryManager, optimize_ultralytics_training_args
from config import TRAINING_CONFIG


class MemoryOptimizationTester:
    """å†…å­˜ä¼˜åŒ–æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.optimizer = MemoryOptimizer()
        self.manager = TrainingMemoryManager(self.optimizer)
        self.test_results = {}
    
    def test_memory_info(self):
        """æµ‹è¯•å†…å­˜ä¿¡æ¯è·å–"""
        print("ğŸ” æµ‹è¯•å†…å­˜ä¿¡æ¯è·å–...")
        
        try:
            memory_info = self.optimizer.get_memory_info()
            
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_fields = ['ram_used_gb', 'ram_total_gb', 'ram_percent', 'timestamp']
            for field in required_fields:
                assert field in memory_info, f"ç¼ºå°‘å­—æ®µ: {field}"
            
            # æ£€æŸ¥æ•°å€¼åˆç†æ€§
            assert 0 <= memory_info['ram_percent'] <= 100, "RAMä½¿ç”¨ç‡è¶…å‡ºåˆç†èŒƒå›´"
            assert memory_info['ram_used_gb'] >= 0, "RAMä½¿ç”¨é‡ä¸èƒ½ä¸ºè´Ÿ"
            assert memory_info['ram_total_gb'] > 0, "RAMæ€»é‡å¿…é¡»å¤§äº0"
            
            print(f"âœ… å†…å­˜ä¿¡æ¯è·å–æ­£å¸¸: RAM {memory_info['ram_used_gb']:.1f}/{memory_info['ram_total_gb']:.1f}GB ({memory_info['ram_percent']:.1f}%)")
            
            # æ£€æŸ¥GPUä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if torch.cuda.is_available():
                assert 'gpu_allocated_gb' in memory_info, "CUDAå¯ç”¨ä½†ç¼ºå°‘GPUå†…å­˜ä¿¡æ¯"
                print(f"âœ… GPUå†…å­˜ä¿¡æ¯æ­£å¸¸: {memory_info['gpu_allocated_gb']:.1f}GB")
            
            if torch.backends.mps.is_available():
                print("âœ… MPSè®¾å¤‡å¯ç”¨")
            
            self.test_results['memory_info'] = True
            return True
            
        except Exception as e:
            print(f"âŒ å†…å­˜ä¿¡æ¯è·å–å¤±è´¥: {e}")
            self.test_results['memory_info'] = False
            return False
    
    def test_memory_cleanup(self):
        """æµ‹è¯•å†…å­˜æ¸…ç†åŠŸèƒ½"""
        print("ğŸ§¹ æµ‹è¯•å†…å­˜æ¸…ç†åŠŸèƒ½...")
        
        try:
            # è·å–æ¸…ç†å‰çš„å†…å­˜ä¿¡æ¯
            before_info = self.optimizer.get_memory_info()
            
            # åˆ›å»ºä¸€äº›å†…å­˜å ç”¨
            test_data = []
            for i in range(1000):
                test_data.append([0] * 1000)  # åˆ›å»ºä¸€äº›å†…å­˜å ç”¨
            
            # æ‰§è¡Œæ¸…ç†
            self.optimizer.cleanup_python_memory()
            self.optimizer.cleanup_gpu_memory()
            
            # åˆ é™¤æµ‹è¯•æ•°æ®
            del test_data
            gc.collect()
            
            # è·å–æ¸…ç†åçš„å†…å­˜ä¿¡æ¯
            after_info = self.optimizer.get_memory_info()
            
            print(f"âœ… å†…å­˜æ¸…ç†å®Œæˆ")
            print(f"   æ¸…ç†å‰: {before_info['ram_percent']:.1f}%")
            print(f"   æ¸…ç†å: {after_info['ram_percent']:.1f}%")
            
            self.test_results['memory_cleanup'] = True
            return True
            
        except Exception as e:
            print(f"âŒ å†…å­˜æ¸…ç†æµ‹è¯•å¤±è´¥: {e}")
            self.test_results['memory_cleanup'] = False
            return False
    
    def test_memory_monitoring(self):
        """æµ‹è¯•å†…å­˜ç›‘æ§åŠŸèƒ½"""
        print("ğŸ“Š æµ‹è¯•å†…å­˜ç›‘æ§åŠŸèƒ½...")
        
        try:
            # å¯åŠ¨ç›‘æ§
            self.optimizer.start_monitoring()
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´æ”¶é›†æ•°æ®
            time.sleep(10)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç›‘æ§æ•°æ®
            assert len(self.optimizer.memory_history) > 0, "æ²¡æœ‰æ”¶é›†åˆ°ç›‘æ§æ•°æ®"
            
            # åœæ­¢ç›‘æ§
            self.optimizer.stop_monitoring()
            
            # ç”ŸæˆæŠ¥å‘Š
            report = self.optimizer.get_memory_report()
            assert "å†…å­˜ä½¿ç”¨æŠ¥å‘Š" in report, "å†…å­˜æŠ¥å‘Šæ ¼å¼ä¸æ­£ç¡®"
            
            print(f"âœ… å†…å­˜ç›‘æ§æ­£å¸¸ï¼Œæ”¶é›†äº† {len(self.optimizer.memory_history)} ä¸ªæ•°æ®ç‚¹")
            print(f"ğŸ“‹ æŠ¥å‘Šé¢„è§ˆ:\n{report}")
            
            self.test_results['memory_monitoring'] = True
            return True
            
        except Exception as e:
            print(f"âŒ å†…å­˜ç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
            self.optimizer.stop_monitoring()  # ç¡®ä¿åœæ­¢ç›‘æ§
            self.test_results['memory_monitoring'] = False
            return False
    
    def test_config_optimization(self):
        """æµ‹è¯•é…ç½®ä¼˜åŒ–åŠŸèƒ½"""
        print("âš™ï¸ æµ‹è¯•é…ç½®ä¼˜åŒ–åŠŸèƒ½...")
        
        try:
            # æµ‹è¯•ä¸åŒè®¾å¤‡çš„é…ç½®ä¼˜åŒ–
            devices = ['cpu']
            if torch.cuda.is_available():
                devices.append('cuda:0')
            if torch.backends.mps.is_available():
                devices.append('mps')
            
            for device in devices:
                print(f"   æµ‹è¯•è®¾å¤‡: {device}")
                
                # è·å–ä¼˜åŒ–é…ç½®
                optimized_config = self.optimizer.optimize_training_config(device, TRAINING_CONFIG)
                
                # æ£€æŸ¥é…ç½®åˆç†æ€§
                assert 'batch_size' in optimized_config, "ç¼ºå°‘batch_sizeé…ç½®"
                assert optimized_config['batch_size'] > 0, "batch_sizeå¿…é¡»å¤§äº0"
                
                print(f"   âœ… {device} é…ç½®ä¼˜åŒ–æ­£å¸¸: batch_size={optimized_config['batch_size']}")
            
            self.test_results['config_optimization'] = True
            return True
            
        except Exception as e:
            print(f"âŒ é…ç½®ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
            self.test_results['config_optimization'] = False
            return False
    
    def test_ultralytics_optimization(self):
        """æµ‹è¯•Ultralyticså‚æ•°ä¼˜åŒ–"""
        print("ğŸ¯ æµ‹è¯•Ultralyticså‚æ•°ä¼˜åŒ–...")
        
        try:
            # æµ‹è¯•å‚æ•°ä¼˜åŒ–
            test_args = {
                'epochs': 100,
                'batch': 16,
                'workers': 8,
                'cache': True,
                'save_period': 5
            }
            
            devices = ['cpu']
            if torch.cuda.is_available():
                devices.append('cuda:0')
            if torch.backends.mps.is_available():
                devices.append('mps')
            
            for device in devices:
                optimized_args = optimize_ultralytics_training_args(test_args, device)
                
                # æ£€æŸ¥ä¼˜åŒ–ç»“æœ
                assert 'cache' in optimized_args, "ç¼ºå°‘cacheé…ç½®"
                assert 'workers' in optimized_args, "ç¼ºå°‘workersé…ç½®"
                
                print(f"   âœ… {device} Ultralyticså‚æ•°ä¼˜åŒ–æ­£å¸¸")
                print(f"      cache: {optimized_args['cache']}")
                print(f"      workers: {optimized_args['workers']}")
            
            self.test_results['ultralytics_optimization'] = True
            return True
            
        except Exception as e:
            print(f"âŒ Ultralyticså‚æ•°ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
            self.test_results['ultralytics_optimization'] = False
            return False
    
    def test_training_memory_manager(self):
        """æµ‹è¯•è®­ç»ƒå†…å­˜ç®¡ç†å™¨"""
        print("ğŸ“ æµ‹è¯•è®­ç»ƒå†…å­˜ç®¡ç†å™¨...")
        
        try:
            # æµ‹è¯•è®­ç»ƒå‰è®¾ç½®
            optimized_config = self.manager.pre_training_setup(TRAINING_CONFIG)
            
            # æ£€æŸ¥é…ç½®
            assert isinstance(optimized_config, dict), "ä¼˜åŒ–é…ç½®å¿…é¡»æ˜¯å­—å…¸"
            assert 'batch_size' in optimized_config, "ç¼ºå°‘batch_sizeé…ç½®"
            
            # æ¨¡æ‹Ÿepochæ¸…ç†
            self.manager.epoch_cleanup(5)
            self.manager.epoch_cleanup(10)  # åº”è¯¥è§¦å‘æ¸…ç†
            
            # æµ‹è¯•è®­ç»ƒåæ¸…ç†
            self.manager.post_training_cleanup()
            
            print("âœ… è®­ç»ƒå†…å­˜ç®¡ç†å™¨æµ‹è¯•æ­£å¸¸")
            
            self.test_results['training_memory_manager'] = True
            return True
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒå†…å­˜ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
            self.test_results['training_memory_manager'] = False
            return False
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹å†…å­˜ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•")
        print("=" * 60)
        
        tests = [
            self.test_memory_info,
            self.test_memory_cleanup,
            self.test_memory_monitoring,
            self.test_config_optimization,
            self.test_ultralytics_optimization,
            self.test_training_memory_manager
        ]
        
        passed = 0
        total = len(tests)
        
        for test in tests:
            try:
                if test():
                    passed += 1
                print()  # ç©ºè¡Œåˆ†éš”
            except Exception as e:
                print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
                print()
        
        # è¾“å‡ºæµ‹è¯•ç»“æœ
        print("=" * 60)
        print("ğŸ“‹ æµ‹è¯•ç»“æœæ±‡æ€»")
        print("=" * 60)
        
        for test_name, result in self.test_results.items():
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"{test_name:25}: {status}")
        
        print(f"\næ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
        
        if passed == total:
            print("ğŸ‰ æ‰€æœ‰å†…å­˜ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
            return True
        else:
            print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
            return False


def main():
    """ä¸»å‡½æ•°"""
    tester = MemoryOptimizationTester()
    success = tester.run_all_tests()
    
    if success:
        print("\nâœ… å†…å­˜ä¼˜åŒ–åŠŸèƒ½æ­£å¸¸ï¼Œå¯ä»¥å®‰å…¨ä½¿ç”¨")
        sys.exit(0)
    else:
        print("\nâŒ å†…å­˜ä¼˜åŒ–åŠŸèƒ½å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥")
        sys.exit(1)


if __name__ == "__main__":
    main()
