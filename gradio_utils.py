"""
Gradioåº”ç”¨çš„å·¥å…·å‡½æ•°
æä¾›æ—¥å¿—ç›‘æ§ã€çŠ¶æ€ç®¡ç†ç­‰åŠŸèƒ½
"""

import os
import time
import threading
import queue
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import io
import base64
from PIL import Image
import json

from config import MODELS_DIR, LOG_CONFIG, DATASETS_DIR


class LogMonitor:
    """æ—¥å¿—ç›‘æ§å™¨"""
    
    def __init__(self):
        self.log_queue = queue.Queue()
        self.is_monitoring = False
        self.monitor_thread = None
        self.current_log_file = None
        
    def start_monitoring(self, log_file_path: str = None):
        """å¼€å§‹ç›‘æ§æ—¥å¿—æ–‡ä»¶"""
        if self.is_monitoring:
            self.stop_monitoring()
            
        if log_file_path is None:
            # æŸ¥æ‰¾æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
            log_file_path = self.find_latest_log()
            
        if log_file_path and Path(log_file_path).exists():
            self.current_log_file = log_file_path
            self.is_monitoring = True
            self.monitor_thread = threading.Thread(target=self._monitor_log_file)
            self.monitor_thread.daemon = True
            self.monitor_thread.start()
            return True
        return False
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=1)
    
    def find_latest_log(self) -> Optional[str]:
        """æŸ¥æ‰¾æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶"""
        # æŸ¥æ‰¾å¯èƒ½çš„æ—¥å¿—ä½ç½®
        possible_dirs = [
            LOG_CONFIG["log_dir"],  # é…ç½®çš„æ—¥å¿—ç›®å½•
            Path("logs"),           # é¡¹ç›®logsç›®å½•
            Path("runs"),           # YOLO runsç›®å½•
            Path("models"),         # æ¨¡å‹ç›®å½•
            Path("."),              # å½“å‰ç›®å½•
        ]

        log_files = []
        for log_dir in possible_dirs:
            if log_dir.exists():
                # æŸ¥æ‰¾å„ç§æ—¥å¿—æ–‡ä»¶
                patterns = ["*.log", "**/*.log", "**/train.log", "**/results.csv"]
                for pattern in patterns:
                    log_files.extend(log_dir.glob(pattern))

        if not log_files:
            return None

        # è¿”å›æœ€æ–°ä¿®æ”¹çš„æ—¥å¿—æ–‡ä»¶
        latest_log = max(log_files, key=lambda x: x.stat().st_mtime)
        return str(latest_log)
    
    def _monitor_log_file(self):
        """ç›‘æ§æ—¥å¿—æ–‡ä»¶çš„å˜åŒ–"""
        try:
            with open(self.current_log_file, 'r', encoding='utf-8') as f:
                # ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾
                f.seek(0, 2)
                
                while self.is_monitoring:
                    line = f.readline()
                    if line:
                        self.log_queue.put(line.strip())
                    else:
                        time.sleep(0.1)
        except Exception as e:
            self.log_queue.put(f"æ—¥å¿—ç›‘æ§é”™è¯¯: {e}")
    
    def get_new_logs(self) -> List[str]:
        """è·å–æ–°çš„æ—¥å¿—è¡Œ"""
        logs = []
        while not self.log_queue.empty():
            try:
                logs.append(self.log_queue.get_nowait())
            except queue.Empty:
                break
        return logs
    
    def get_recent_logs(self, num_lines: int = 100) -> List[str]:
        """è·å–æœ€è¿‘çš„æ—¥å¿—å†…å®¹"""
        if not self.current_log_file or not Path(self.current_log_file).exists():
            return ["æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶"]

        try:
            with open(self.current_log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                recent_lines = lines[-num_lines:] if len(lines) > num_lines else lines
                return [line.strip() for line in recent_lines if line.strip()]
        except Exception as e:
            return [f"è¯»å–æ—¥å¿—æ–‡ä»¶é”™è¯¯: {e}"]

    def get_recent_logs_as_string(self, num_lines: int = 100) -> str:
        """è·å–æœ€è¿‘çš„æ—¥å¿—å†…å®¹ä½œä¸ºå­—ç¬¦ä¸²"""
        logs = self.get_recent_logs(num_lines)
        return '\n'.join(logs)


class TrainingMonitor:
    """è®­ç»ƒç›‘æ§å™¨"""
    
    def __init__(self):
        self.current_training_dir = None
        
    def find_latest_training(self) -> Optional[Path]:
        """æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒç›®å½•"""
        train_dirs = list(MODELS_DIR.glob("train*"))
        if not train_dirs:
            return None
        return max(train_dirs, key=lambda x: x.stat().st_mtime)
    
    def get_training_status(self) -> Dict:
        """è·å–è®­ç»ƒçŠ¶æ€"""
        latest_dir = self.find_latest_training()
        if not latest_dir:
            return {"status": "no_training", "message": "æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒè®°å½•"}
        
        results_file = latest_dir / "results.csv"
        if not results_file.exists():
            return {"status": "no_results", "message": "è®­ç»ƒç»“æœæ–‡ä»¶ä¸å­˜åœ¨"}
        
        try:
            df = pd.read_csv(results_file)
            if len(df) == 0:
                return {"status": "empty_results", "message": "è®­ç»ƒç»“æœä¸ºç©º"}
            
            latest = df.iloc[-1]
            return {
                "status": "active",
                "epochs": len(df),
                "latest_metrics": {
                    "box_loss": latest.get('train/box_loss', 0),
                    "cls_loss": latest.get('train/cls_loss', 0),
                    "dfl_loss": latest.get('train/dfl_loss', 0),
                    "map50": latest.get('metrics/mAP50(B)', 0),
                    "map50_95": latest.get('metrics/mAP50-95(B)', 0)
                },
                "training_dir": str(latest_dir)
            }
        except Exception as e:
            return {"status": "error", "message": f"è¯»å–è®­ç»ƒç»“æœé”™è¯¯: {e}"}
    
    def generate_training_plot(self) -> Optional[str]:
        """ç”Ÿæˆè®­ç»ƒæ›²çº¿å›¾"""
        latest_dir = self.find_latest_training()
        if not latest_dir:
            return None
            
        results_file = latest_dir / "results.csv"
        if not results_file.exists():
            return None
        
        try:
            df = pd.read_csv(results_file)
            if len(df) == 0:
                return None
            
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))
            epochs = df.index + 1
            
            # Box Loss
            if 'train/box_loss' in df.columns:
                ax1.plot(epochs, df['train/box_loss'], 'b-', linewidth=2)
                ax1.set_title('Box Loss')
                ax1.set_xlabel('Epoch')
                ax1.set_ylabel('Loss')
                ax1.grid(True, alpha=0.3)
            
            # Class Loss
            if 'train/cls_loss' in df.columns:
                ax2.plot(epochs, df['train/cls_loss'], 'r-', linewidth=2)
                ax2.set_title('Class Loss')
                ax2.set_xlabel('Epoch')
                ax2.set_ylabel('Loss')
                ax2.grid(True, alpha=0.3)
            
            # DFL Loss
            if 'train/dfl_loss' in df.columns:
                ax3.plot(epochs, df['train/dfl_loss'], 'g-', linewidth=2)
                ax3.set_title('DFL Loss')
                ax3.set_xlabel('Epoch')
                ax3.set_ylabel('Loss')
                ax3.grid(True, alpha=0.3)
            
            # mAP50
            if 'metrics/mAP50(B)' in df.columns:
                ax4.plot(epochs, df['metrics/mAP50(B)'], 'purple', linewidth=2)
                ax4.set_title('mAP50')
                ax4.set_xlabel('Epoch')
                ax4.set_ylabel('mAP50')
                ax4.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ä¿å­˜ä¸ºbase64å­—ç¬¦ä¸²
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            plot_data = buffer.getvalue()
            buffer.close()
            plt.close()
            
            # è½¬æ¢ä¸ºbase64
            plot_base64 = base64.b64encode(plot_data).decode()
            return f"data:image/png;base64,{plot_base64}"
            
        except Exception as e:
            print(f"ç”Ÿæˆè®­ç»ƒæ›²çº¿é”™è¯¯: {e}")
            return None


class DatasetManager:
    """æ•°æ®é›†ç®¡ç†å™¨"""
    
    def get_dataset_info(self) -> Dict:
        """è·å–æ•°æ®é›†ä¿¡æ¯"""
        info = {
            "train": {"images": 0, "labels": 0},
            "val": {"images": 0, "labels": 0},
            "test": {"images": 0, "labels": 0}
        }
        
        for split in ["train", "val", "test"]:
            images_dir = DATASETS_DIR / "images" / split
            labels_dir = DATASETS_DIR / "labels" / split
            
            if images_dir.exists():
                image_files = []
                for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
                    image_files.extend(images_dir.glob(ext))
                info[split]["images"] = len(image_files)
            
            if labels_dir.exists():
                label_files = list(labels_dir.glob("*.txt"))
                info[split]["labels"] = len(label_files)
        
        return info
    
    def get_sample_images(self, split: str = "train", num_samples: int = 5) -> List[str]:
        """è·å–æ ·æœ¬å›¾ç‰‡è·¯å¾„"""
        images_dir = DATASETS_DIR / "images" / split
        if not images_dir.exists():
            return []
        
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            image_files.extend(images_dir.glob(ext))
        
        if len(image_files) > num_samples:
            import random
            image_files = random.sample(image_files, num_samples)
        
        return [str(f) for f in image_files]


class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨"""
    
    def get_available_models(self) -> List[str]:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        model_files = []
        for pattern in ["**/*.pt", "**/*best.pt", "**/best.pt"]:
            model_files.extend(MODELS_DIR.glob(pattern))

        # è¿”å›ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
        project_root = Path(__file__).parent  # é¡¹ç›®æ ¹ç›®å½•
        relative_paths = []

        for model_file in model_files:
            try:
                # è®¡ç®—ç›¸å¯¹è·¯å¾„
                relative_path = model_file.relative_to(project_root)
                relative_paths.append(str(relative_path))
            except ValueError:
                # å¦‚æœæ— æ³•è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„
                relative_paths.append(str(model_file))

        return relative_paths

    def get_absolute_path(self, relative_path: str) -> str:
        """å°†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„"""
        if Path(relative_path).is_absolute():
            # å¦‚æœå·²ç»æ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æ¥è¿”å›
            return relative_path

        # ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
        project_root = Path(__file__).parent
        absolute_path = project_root / relative_path

        return str(absolute_path)

    def get_model_info(self, model_path: str) -> Dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        model_path = Path(model_path)
        if not model_path.exists():
            return {"error": "æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨"}
        
        try:
            stat = model_path.stat()
            return {
                "name": model_path.name,
                "size": f"{stat.st_size / (1024*1024):.2f} MB",
                "modified": time.ctime(stat.st_mtime),
                "path": str(model_path)
            }
        except Exception as e:
            return {"error": f"è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {e}"}

    def export_model(self, model_path: str, format: str = "onnx") -> str:
        """
        å¯¼å‡ºæ¨¡å‹ä¸ºå…¶ä»–æ ¼å¼
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
            format: å¯¼å‡ºæ ¼å¼ (onnx, torchscript, tfliteç­‰)
            
        Returns:
            å¯¼å‡ºçš„æ¨¡å‹è·¯å¾„
        """
        try:
            from ultralytics import YOLO
            
            model_path = Path(model_path)
            if not model_path.exists():
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            
            print(f"ğŸ”„ æ­£åœ¨å¯¼å‡ºæ¨¡å‹ä¸º {format} æ ¼å¼...")
            print(f"ğŸ“ æºæ¨¡å‹è·¯å¾„: {model_path}")
            
            # åŠ è½½æ¨¡å‹
            model = YOLO(str(model_path))
            
            # å¯¼å‡ºæ¨¡å‹
            export_path = model.export(format=format)
            
            print(f"âœ… æ¨¡å‹å·²æˆåŠŸå¯¼å‡ºåˆ°: {export_path}")
            
            return str(export_path)
            
        except ImportError:
            raise ImportError("æœªå®‰è£…ultralyticsåº“ï¼Œè¯·è¿è¡Œ: pip install ultralytics")
        except Exception as e:
            error_msg = f"å¯¼å‡ºæ¨¡å‹æ—¶å‡ºé”™: {e}"
            print(f"âŒ {error_msg}")
            raise Exception(error_msg)

    def generate_yaml_config(self, model_path: str, template_type: str, 
                           input_width: int = 640, input_height: int = 640,
                           confidence_threshold: float = 0.45, nms_threshold: float = 0.45) -> str:
        """
        ç”ŸæˆX-AnyLabelingçš„YAMLé…ç½®æ–‡ä»¶
        
        Args:
            model_path: ONNXæ¨¡å‹è·¯å¾„
            template_type: æ¨¡æ¿ç±»å‹ (rtdetr, yolov6_face, yolov5_cls, yolo_det)
            input_width: è¾“å…¥å®½åº¦
            input_height: è¾“å…¥é«˜åº¦
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            nms_threshold: NMSé˜ˆå€¼
            
        Returns:
            ç”Ÿæˆçš„YAMLé…ç½®æ–‡ä»¶è·¯å¾„
        """
        try:
            from class_manager import class_manager
            import yaml
            from datetime import datetime
            
            model_path = Path(model_path)
            if not model_path.exists():
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            
            # è·å–ç±»åˆ«ä¿¡æ¯
            class_names = class_manager.get_class_names()
            if not class_names:
                # å¦‚æœæ²¡æœ‰ç±»åˆ«ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤çš„COCOç±»åˆ«
                class_names = [
                    "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck",
                    "boat", "traffic light", "fire hydrant", "stop sign", "parking meter", "bench"
                ]
                print("âš ï¸ æœªæ‰¾åˆ°ç±»åˆ«ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤COCOç±»åˆ«")
            
            # ç”Ÿæˆé…ç½®å†…å®¹
            config = self._generate_config_by_template(
                template_type, model_path, class_names, 
                input_width, input_height, confidence_threshold, nms_threshold
            )
            
            # ç”Ÿæˆé…ç½®æ–‡ä»¶è·¯å¾„
            yaml_path = model_path.with_suffix('.yaml')
            
            # ä¿å­˜YAMLæ–‡ä»¶
            with open(yaml_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
            
            print(f"âœ… YAMLé…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {yaml_path}")
            return str(yaml_path)
            
        except Exception as e:
            error_msg = f"ç”ŸæˆYAMLé…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}"
            print(f"âŒ {error_msg}")
            raise Exception(error_msg)

    def _generate_config_by_template(self, template_type: str, model_path: Path, 
                                   class_names: list, input_width: int, input_height: int,
                                   confidence_threshold: float, nms_threshold: float) -> dict:
        """æ ¹æ®æ¨¡æ¿ç±»å‹ç”Ÿæˆé…ç½®"""
        from datetime import datetime
        
        model_name = model_path.stem
        timestamp = datetime.now().strftime("%Y%m%d")
        
        if template_type == "rtdetr":
            return {
                "type": "rtdetr",
                "name": f"{model_name}-r{timestamp}",
                "display_name": f"RT-DETR ({model_name})",
                "model_path": str(model_path.absolute()),
                "input_width": input_width,
                "input_height": input_height,
                "score_threshold": confidence_threshold,
                "classes": class_names
            }
        
        elif template_type == "yolov6_face":
            return {
                "type": "yolov6_face",
                "name": f"{model_name}-r{timestamp}",
                "display_name": f"YOLOv6-Face ({model_name})",
                "model_path": str(model_path.absolute()),
                "input_width": input_width,
                "input_height": input_height,
                "stride": 64,
                "nms_threshold": nms_threshold,
                "confidence_threshold": confidence_threshold,
                "classes": class_names,
                "five_key_points_classes": [
                    "left_eye", "right_eye", "nose_tip", "left_mouth_corner", "right_mouth_corner"
                ]
            }
        
        elif template_type == "yolov5_cls":
            # è¿™æ˜¯æ£€æµ‹+åˆ†ç±»çº§è”æ¨¡æ¿ï¼Œéœ€è¦ä¸¤ä¸ªæ¨¡å‹è·¯å¾„
            return {
                "type": "yolov5_cls",
                "name": f"{model_name}-r{timestamp}",
                "display_name": f"YOLOv5-Cls ({model_name})",
                "det_model_path": str(model_path.absolute()),
                "cls_model_path": "path/to/classification/model.onnx",  # éœ€è¦ç”¨æˆ·æ‰‹åŠ¨ä¿®æ”¹
                "det_input_width": input_width,
                "det_input_height": input_height,
                "cls_input_width": 224,
                "cls_input_height": 224,
                "cls_score_threshold": 0.5,
                "stride": 32,
                "nms_threshold": nms_threshold,
                "confidence_threshold": confidence_threshold,
                "det_classes": class_names,
                "cls_classes": {
                    0: "class_0",
                    1: "class_1",
                    2: "class_2"
                }
            }
        
        else:  # yolo_det æ ‡å‡†YOLOæ£€æµ‹
            return {
                "type": "yolov8",
                "name": f"{model_name}-r{timestamp}",
                "display_name": f"yoloV8-{model_name}",
                "model_path": str(model_path.absolute()),
                "input_width": input_width,
                "input_height": input_height,
                "stride": 32,
                "nms_threshold": nms_threshold,
                "confidence_threshold": confidence_threshold,
                "classes": class_names
            }


# å…¨å±€å®ä¾‹
log_monitor = LogMonitor()
training_monitor = TrainingMonitor()
dataset_manager = DatasetManager()
model_manager = ModelManager()
